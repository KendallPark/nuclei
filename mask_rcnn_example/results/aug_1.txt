[kendall@imgaug-1 mask-rcnn-example]$ pipenv run python nucleus.py train --dataset=../data/ --subset=train --weights=none
/home/kendall/.local/share/virtualenvs/nuclei-rbrbKAr7/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Weights:  none
Dataset:  ../data/
Subset:  train
Logs:  /home/kendall/nuclei/mask-rcnn-example/logs

Configurations:
BACKBONE                       resnet50
BACKBONE_STRIDES               [4, 8, 16, 32, 64]
BATCH_SIZE                     6
BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]
DETECTION_MAX_INSTANCES        400
DETECTION_MIN_CONFIDENCE       0
DETECTION_NMS_THRESHOLD        0.3
GPU_COUNT                      1
GRADIENT_CLIP_NORM             5.0
IMAGES_PER_GPU                 6
IMAGE_MAX_DIM                  128
IMAGE_META_SIZE                14
IMAGE_MIN_DIM                  128
IMAGE_MIN_SCALE                2.0
IMAGE_RESIZE_MODE              square
IMAGE_SHAPE                    [128 128   3]
LEARNING_MOMENTUM              0.9
LEARNING_RATE                  0.001
LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}
MASK_POOL_SIZE                 14
MASK_SHAPE                     [28, 28]
MAX_GT_INSTANCES               200
MEAN_PIXEL                     [43.53 39.56 48.22]
MINI_MASK_SHAPE                (56, 56)
NAME                           nucleus
NUM_CLASSES                    2
POOL_SIZE                      7
POST_NMS_ROIS_INFERENCE        2000
POST_NMS_ROIS_TRAINING         1000
ROI_POSITIVE_RATIO             0.33
RPN_ANCHOR_RATIOS              [0.5, 1, 2]
RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)
RPN_ANCHOR_STRIDE              1
RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]
RPN_NMS_THRESHOLD              0.9
RPN_TRAIN_ANCHORS_PER_IMAGE    64
STEPS_PER_EPOCH                98
TRAIN_BN                       False
TRAIN_ROIS_PER_IMAGE           128
USE_MINI_MASK                  True
USE_RPN_ROIS                   True
VALIDATION_STEPS               11
WEIGHT_DECAY                   0.0001


Loading weights  none
Train network heads
WARNING:tensorflow:From /home/kendall/.local/share/virtualenvs/nuclei-rbrbKAr7/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.

Starting at epoch 0. LR=0.001

Checkpoint Path: /home/kendall/nuclei/mask-rcnn-example/logs/nucleus20180504T1717/mask_rcnn_nucleus_{epoch:04d}.h5
Selecting layers to train
fpn_c5p5               (Conv2D)
fpn_c4p4               (Conv2D)
fpn_c3p3               (Conv2D)
fpn_c2p2               (Conv2D)
fpn_p5                 (Conv2D)
fpn_p2                 (Conv2D)
fpn_p3                 (Conv2D)
fpn_p4                 (Conv2D)
In model:  rpn_model
    rpn_conv_shared        (Conv2D)
    rpn_class_raw          (Conv2D)
    rpn_bbox_pred          (Conv2D)
mrcnn_mask_conv1       (TimeDistributed)
mrcnn_mask_bn1         (TimeDistributed)
mrcnn_mask_conv2       (TimeDistributed)
mrcnn_mask_bn2         (TimeDistributed)
mrcnn_class_conv1      (TimeDistributed)
mrcnn_class_bn1        (TimeDistributed)
mrcnn_mask_conv3       (TimeDistributed)
mrcnn_mask_bn3         (TimeDistributed)
mrcnn_class_conv2      (TimeDistributed)
mrcnn_class_bn2        (TimeDistributed)
mrcnn_mask_conv4       (TimeDistributed)
mrcnn_mask_bn4         (TimeDistributed)
mrcnn_bbox_fc          (TimeDistributed)
mrcnn_mask_deconv      (TimeDistributed)
mrcnn_class_logits     (TimeDistributed)
mrcnn_mask             (TimeDistributed)
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Epoch 1/20
98/98 [==============================] - 7109s 73s/step - loss: 6.6753 - rpn_class_loss: 1.3979 - rpn_bbox_loss: 3.2972 - mrcnn_class_loss: 0.1548 - mrcnn_bbox_loss: 1.1308 - mrcnn_mask_loss: 0.6947 - val_loss: 4.8884 - val_rpn_class_loss: 0.8372 - val_rpn_bbox_loss: 2.1859 - val_mrcnn_class_loss: 0.3339 - val_mrcnn_bbox_loss: 0.8836 - val_mrcnn_mask_loss: 0.6478
Epoch 2/20
98/98 [==============================] - 6932s 71s/step - loss: 4.1565 - rpn_class_loss: 0.7196 - rpn_bbox_loss: 1.8786 - mrcnn_class_loss: 0.1979 - mrcnn_bbox_loss: 0.7216 - mrcnn_mask_loss: 0.6387 - val_loss: 3.4558 - val_rpn_class_loss: 0.5364 - val_rpn_bbox_loss: 1.4357 - val_mrcnn_class_loss: 0.2829 - val_mrcnn_bbox_loss: 0.5823 - val_mrcnn_mask_loss: 0.6186
Epoch 3/20
98/98 [==============================] - 7025s 72s/step - loss: 3.4220 - rpn_class_loss: 0.5247 - rpn_bbox_loss: 1.4065 - mrcnn_class_loss: 0.2413 - mrcnn_bbox_loss: 0.6373 - mrcnn_mask_loss: 0.6122 - val_loss: 3.2016 - val_rpn_class_loss: 0.4737 - val_rpn_bbox_loss: 1.2399 - val_mrcnn_class_loss: 0.2712 - val_mrcnn_bbox_loss: 0.6242 - val_mrcnn_mask_loss: 0.5926
Epoch 4/20
98/98 [==============================] - 6983s 71s/step - loss: 3.1484 - rpn_class_loss: 0.4549 - rpn_bbox_loss: 1.2611 - mrcnn_class_loss: 0.2695 - mrcnn_bbox_loss: 0.5725 - mrcnn_mask_loss: 0.5904 - val_loss: 2.8971 - val_rpn_class_loss: 0.3963 - val_rpn_bbox_loss: 1.1104 - val_mrcnn_class_loss: 0.3005 - val_mrcnn_bbox_loss: 0.5253 - val_mrcnn_mask_loss: 0.5647
Epoch 5/20
98/98 [==============================] - 6715s 69s/step - loss: 2.9056 - rpn_class_loss: 0.3989 - rpn_bbox_loss: 1.1159 - mrcnn_class_loss: 0.2834 - mrcnn_bbox_loss: 0.5382 - mrcnn_mask_loss: 0.5692 - val_loss: 2.7291 - val_rpn_class_loss: 0.3848 - val_rpn_bbox_loss: 1.0468 - val_mrcnn_class_loss: 0.2798 - val_mrcnn_bbox_loss: 0.4779 - val_mrcnn_mask_loss: 0.5399
Epoch 6/20
98/98 [==============================] - 6630s 68s/step - loss: 2.7585 - rpn_class_loss: 0.3761 - rpn_bbox_loss: 1.0589 - mrcnn_class_loss: 0.2768 - mrcnn_bbox_loss: 0.4882 - mrcnn_mask_loss: 0.5585 - val_loss: 2.9048 - val_rpn_class_loss: 0.4158 - val_rpn_bbox_loss: 1.0258 - val_mrcnn_class_loss: 0.4227 - val_mrcnn_bbox_loss: 0.4967 - val_mrcnn_mask_loss: 0.5438
Epoch 7/20
98/98 [==============================] - 6435s 66s/step - loss: 2.6488 - rpn_class_loss: 0.3368 - rpn_bbox_loss: 0.9615 - mrcnn_class_loss: 0.2977 - mrcnn_bbox_loss: 0.5074 - mrcnn_mask_loss: 0.5454 - val_loss: 2.4767 - val_rpn_class_loss: 0.3089 - val_rpn_bbox_loss: 0.8302 - val_mrcnn_class_loss: 0.3186 - val_mrcnn_bbox_loss: 0.4892 - val_mrcnn_mask_loss: 0.5297
Epoch 9/20
98/98 [==============================] - 6632s 68s/step - loss: 2.5203 - rpn_class_loss: 0.3112 - rpn_bbox_loss: 0.9150 - mrcnn_class_loss: 0.2938 - mrcnn_bbox_loss: 0.4670 - mrcnn_mask_loss: 0.5333 - val_loss: 2.5008 - val_rpn_class_loss: 0.3104 - val_rpn_bbox_loss: 0.8493 - val_mrcnn_class_loss: 0.3006 - val_mrcnn_bbox_loss: 0.5276 - val_mrcnn_mask_loss: 0.5129
Epoch 10/20
98/98 [==============================] - 6728s 69s/step - loss: 2.4160 - rpn_class_loss: 0.2881 - rpn_bbox_loss: 0.8679 - mrcnn_class_loss: 0.2902 - mrcnn_bbox_loss: 0.4452 - mrcnn_mask_loss: 0.5247 - val_loss: 2.4672 - val_rpn_class_loss: 0.3171 - val_rpn_bbox_loss: 0.8334 - val_mrcnn_class_loss: 0.2954 - val_mrcnn_bbox_loss: 0.4942 - val_mrcnn_mask_loss: 0.5271
Epoch 11/20
98/98 [==============================] - 6858s 70s/step - loss: 2.3569 - rpn_class_loss: 0.2945 - rpn_bbox_loss: 0.8427 - mrcnn_class_loss: 0.2807 - mrcnn_bbox_loss: 0.4261 - mrcnn_mask_loss: 0.5129 - val_loss: 2.2107 - val_rpn_class_loss: 0.2660 - val_rpn_bbox_loss: 0.7234 - val_mrcnn_class_loss: 0.2913 - val_mrcnn_bbox_loss: 0.4322 - val_mrcnn_mask_loss: 0.4977
Epoch 12/20
98/98 [==============================] - 7010s 72s/step - loss: 2.3382 - rpn_class_loss: 0.2648 - rpn_bbox_loss: 0.8475 - mrcnn_class_loss: 0.2914 - mrcnn_bbox_loss: 0.4232 - mrcnn_mask_loss: 0.5112 - val_loss: 2.3805 - val_rpn_class_loss: 0.2961 - val_rpn_bbox_loss: 0.8611 - val_mrcnn_class_loss: 0.3241 - val_mrcnn_bbox_loss: 0.4096 - val_mrcnn_mask_loss: 0.4896
Epoch 13/20
98/98 [==============================] - 7180s 73s/step - loss: 2.3313 - rpn_class_loss: 0.2714 - rpn_bbox_loss: 0.8472 - mrcnn_class_loss: 0.2905 - mrcnn_bbox_loss: 0.4141 - mrcnn_mask_loss: 0.5080 - val_loss: 2.2668 - val_rpn_class_loss: 0.2724 - val_rpn_bbox_loss: 0.7533 - val_mrcnn_class_loss: 0.3093 - val_mrcnn_bbox_loss: 0.4336 - val_mrcnn_mask_loss: 0.4983
Epoch 14/20
98/98 [==============================] - 7196s 73s/step - loss: 2.2152 - rpn_class_loss: 0.2469 - rpn_bbox_loss: 0.7844 - mrcnn_class_loss: 0.2873 - mrcnn_bbox_loss: 0.3990 - mrcnn_mask_loss: 0.4975 - val_loss: 2.0772 - val_rpn_class_loss: 0.2265 - val_rpn_bbox_loss: 0.7055 - val_mrcnn_class_loss: 0.2599 - val_mrcnn_bbox_loss: 0.3908 - val_mrcnn_mask_loss: 0.4944
Epoch 15/20
98/98 [==============================] - 7094s 72s/step - loss: 2.2504 - rpn_class_loss: 0.2547 - rpn_bbox_loss: 0.8106 - mrcnn_class_loss: 0.2771 - mrcnn_bbox_loss: 0.4089 - mrcnn_mask_loss: 0.4992 - val_loss: 2.1950 - val_rpn_class_loss: 0.2452 - val_rpn_bbox_loss: 0.7591 - val_mrcnn_class_loss: 0.2973 - val_mrcnn_bbox_loss: 0.4095 - val_mrcnn_mask_loss: 0.4839
Epoch 16/20
98/98 [==============================] - 6985s 71s/step - loss: 2.2496 - rpn_class_loss: 0.2571 - rpn_bbox_loss: 0.8290 - mrcnn_class_loss: 0.2732 - mrcnn_bbox_loss: 0.3961 - mrcnn_mask_loss: 0.4943 - val_loss: 2.0932 - val_rpn_class_loss: 0.2727 - val_rpn_bbox_loss: 0.6853 - val_mrcnn_class_loss: 0.2911 - val_mrcnn_bbox_loss: 0.3817 - val_mrcnn_mask_loss: 0.4624
Epoch 17/20
98/98 [==============================] - 6842s 70s/step - loss: 2.2095 - rpn_class_loss: 0.2436 - rpn_bbox_loss: 0.7952 - mrcnn_class_loss: 0.2820 - mrcnn_bbox_loss: 0.3948 - mrcnn_mask_loss: 0.4938 - val_loss: 2.1096 - val_rpn_class_loss: 0.2435 - val_rpn_bbox_loss: 0.7140 - val_mrcnn_class_loss: 0.2980 - val_mrcnn_bbox_loss: 0.3872 - val_mrcnn_mask_loss: 0.4670
Epoch 18/20
98/98 [==============================] - 6827s 70s/step - loss: 2.1448 - rpn_class_loss: 0.2294 - rpn_bbox_loss: 0.7512 - mrcnn_class_loss: 0.2818 - mrcnn_bbox_loss: 0.3936 - mrcnn_mask_loss: 0.4888 - val_loss: 2.1712 - val_rpn_class_loss: 0.2774 - val_rpn_bbox_loss: 0.7176 - val_mrcnn_class_loss: 0.3012 - val_mrcnn_bbox_loss: 0.4068 - val_mrcnn_mask_loss: 0.4682
Epoch 19/20
98/98 [==============================] - 6852s 70s/step - loss: 2.0806 - rpn_class_loss: 0.2315 - rpn_bbox_loss: 0.7247 - mrcnn_class_loss: 0.2812 - mrcnn_bbox_loss: 0.3697 - mrcnn_mask_loss: 0.4735 - val_loss: 2.1372 - val_rpn_class_loss: 0.2282 - val_rpn_bbox_loss: 0.6798 - val_mrcnn_class_loss: 0.3582 - val_mrcnn_bbox_loss: 0.3947 - val_mrcnn_mask_loss: 0.4763
Epoch 20/20
98/98 [==============================] - 6626s 68s/step - loss: 2.1181 - rpn_class_loss: 0.2242 - rpn_bbox_loss: 0.7475 - mrcnn_class_loss: 0.2912 - mrcnn_bbox_loss: 0.3776 - mrcnn_mask_loss: 0.4775 - val_loss: 1.9026 - val_rpn_class_loss: 0.2033 - val_rpn_bbox_loss: 0.6037 - val_mrcnn_class_loss: 0.2850 - val_mrcnn_bbox_loss: 0.3613 - val_mrcnn_mask_loss: 0.4493
Train all layers

Starting at epoch 20. LR=0.001

Checkpoint Path: /home/kendall/nuclei/mask-rcnn-example/logs/nucleus20180504T1717/mask_rcnn_nucleus_{epoch:04d}.h5
Selecting layers to train
conv1                  (Conv2D)
bn_conv1               (BatchNorm)
res2a_branch2a         (Conv2D)
bn2a_branch2a          (BatchNorm)
res2a_branch2b         (Conv2D)
bn2a_branch2b          (BatchNorm)
res2a_branch2c         (Conv2D)
res2a_branch1          (Conv2D)
bn2a_branch2c          (BatchNorm)
bn2a_branch1           (BatchNorm)
res2b_branch2a         (Conv2D)
bn2b_branch2a          (BatchNorm)
res2b_branch2b         (Conv2D)
bn2b_branch2b          (BatchNorm)
res2b_branch2c         (Conv2D)
bn2b_branch2c          (BatchNorm)
res2c_branch2a         (Conv2D)
bn2c_branch2a          (BatchNorm)
res2c_branch2b         (Conv2D)
bn2c_branch2b          (BatchNorm)
res2c_branch2c         (Conv2D)
bn2c_branch2c          (BatchNorm)
res3a_branch2a         (Conv2D)
bn3a_branch2a          (BatchNorm)
res3a_branch2b         (Conv2D)
bn3a_branch2b          (BatchNorm)
res3a_branch2c         (Conv2D)
res3a_branch1          (Conv2D)
bn3a_branch2c          (BatchNorm)
bn3a_branch1           (BatchNorm)
res3b_branch2a         (Conv2D)
bn3b_branch2a          (BatchNorm)
res3b_branch2b         (Conv2D)
bn3b_branch2b          (BatchNorm)
res3b_branch2c         (Conv2D)
bn3b_branch2c          (BatchNorm)
res3c_branch2a         (Conv2D)
bn3c_branch2a          (BatchNorm)
res3c_branch2b         (Conv2D)
bn3c_branch2b          (BatchNorm)
res3c_branch2c         (Conv2D)
bn3c_branch2c          (BatchNorm)
res3d_branch2a         (Conv2D)
bn3d_branch2a          (BatchNorm)
res3d_branch2b         (Conv2D)
bn3d_branch2b          (BatchNorm)
res3d_branch2c         (Conv2D)
bn3d_branch2c          (BatchNorm)
res4a_branch2a         (Conv2D)
bn4a_branch2a          (BatchNorm)
res4a_branch2b         (Conv2D)
bn4a_branch2b          (BatchNorm)
res4a_branch2c         (Conv2D)
res4a_branch1          (Conv2D)
bn4a_branch2c          (BatchNorm)
bn4a_branch1           (BatchNorm)
res4b_branch2a         (Conv2D)
bn4b_branch2a          (BatchNorm)
res4b_branch2b         (Conv2D)
bn4b_branch2b          (BatchNorm)
res4b_branch2c         (Conv2D)
bn4b_branch2c          (BatchNorm)
res4c_branch2a         (Conv2D)
bn4c_branch2a          (BatchNorm)
res4c_branch2b         (Conv2D)
bn4c_branch2b          (BatchNorm)
res4c_branch2c         (Conv2D)
bn4c_branch2c          (BatchNorm)
res4d_branch2a         (Conv2D)
bn4d_branch2a          (BatchNorm)
res4d_branch2b         (Conv2D)
bn4d_branch2b          (BatchNorm)
res4d_branch2c         (Conv2D)
bn4d_branch2c          (BatchNorm)
res4e_branch2a         (Conv2D)
bn4e_branch2a          (BatchNorm)
res4e_branch2b         (Conv2D)
bn4e_branch2b          (BatchNorm)
res4e_branch2c         (Conv2D)
bn4e_branch2c          (BatchNorm)
res4f_branch2a         (Conv2D)
bn4f_branch2a          (BatchNorm)
res4f_branch2b         (Conv2D)
bn4f_branch2b          (BatchNorm)
res4f_branch2c         (Conv2D)
bn4f_branch2c          (BatchNorm)
res5a_branch2a         (Conv2D)
bn5a_branch2a          (BatchNorm)
res5a_branch2b         (Conv2D)
bn5a_branch2b          (BatchNorm)
res5a_branch2c         (Conv2D)
res5a_branch1          (Conv2D)
bn5a_branch2c          (BatchNorm)
bn5a_branch1           (BatchNorm)
res5b_branch2a         (Conv2D)
bn5b_branch2a          (BatchNorm)
res5b_branch2b         (Conv2D)
bn5b_branch2b          (BatchNorm)
res5b_branch2c         (Conv2D)
bn5b_branch2c          (BatchNorm)
res5c_branch2a         (Conv2D)
bn5c_branch2a          (BatchNorm)
res5c_branch2b         (Conv2D)
bn5c_branch2b          (BatchNorm)
res5c_branch2c         (Conv2D)
bn5c_branch2c          (BatchNorm)
fpn_c5p5               (Conv2D)
fpn_c4p4               (Conv2D)
fpn_c3p3               (Conv2D)
fpn_c2p2               (Conv2D)
fpn_p5                 (Conv2D)
fpn_p2                 (Conv2D)
fpn_p3                 (Conv2D)
fpn_p4                 (Conv2D)
In model:  rpn_model
    rpn_conv_shared        (Conv2D)
    rpn_class_raw          (Conv2D)
    rpn_bbox_pred          (Conv2D)
mrcnn_mask_conv1       (TimeDistributed)
mrcnn_mask_bn1         (TimeDistributed)
mrcnn_mask_conv2       (TimeDistributed)
mrcnn_mask_bn2         (TimeDistributed)
mrcnn_class_conv1      (TimeDistributed)
mrcnn_class_bn1        (TimeDistributed)
mrcnn_mask_conv3       (TimeDistributed)
mrcnn_mask_bn3         (TimeDistributed)
mrcnn_class_conv2      (TimeDistributed)
mrcnn_class_bn2        (TimeDistributed)
mrcnn_mask_conv4       (TimeDistributed)
mrcnn_mask_bn4         (TimeDistributed)
mrcnn_bbox_fc          (TimeDistributed)
mrcnn_mask_deconv      (TimeDistributed)
mrcnn_class_logits     (TimeDistributed)
mrcnn_mask             (TimeDistributed)
Epoch 21/80
98/98 [==============================] - 6753s 69s/step - loss: 2.1242 - rpn_class_loss: 0.2378 - rpn_bbox_loss: 0.7445 - mrcnn_class_loss: 0.2799 - mrcnn_bbox_loss: 0.3823 - mrcnn_mask_loss: 0.4797 - val_loss: 1.9326 - val_rpn_class_loss: 0.2222 - val_rpn_bbox_loss: 0.6404 - val_mrcnn_class_loss: 0.2706 - val_mrcnn_bbox_loss: 0.3617 - val_mrcnn_mask_loss: 0.4376
Epoch 22/80
98/98 [==============================] - 6730s 69s/step - loss: 2.0922 - rpn_class_loss: 0.2259 - rpn_bbox_loss: 0.7388 - mrcnn_class_loss: 0.2814 - mrcnn_bbox_loss: 0.3764 - mrcnn_mask_loss: 0.4697 - val_loss: 1.8820 - val_rpn_class_loss: 0.1923 - val_rpn_bbox_loss: 0.5771 - val_mrcnn_class_loss: 0.3070 - val_mrcnn_bbox_loss: 0.3525 - val_mrcnn_mask_loss: 0.4530
Epoch 23/80
98/98 [==============================] - 6727s 69s/step - loss: 2.0240 - rpn_class_loss: 0.2205 - rpn_bbox_loss: 0.6939 - mrcnn_class_loss: 0.2839 - mrcnn_bbox_loss: 0.3644 - mrcnn_mask_loss: 0.4613 - val_loss: 1.8838 - val_rpn_class_loss: 0.2046 - val_rpn_bbox_loss: 0.6144 - val_mrcnn_class_loss: 0.2700 - val_mrcnn_bbox_loss: 0.3531 - val_mrcnn_mask_loss: 0.4417
Epoch 24/80
98/98 [==============================] - 6748s 69s/step - loss: 1.9550 - rpn_class_loss: 0.2156 - rpn_bbox_loss: 0.6879 - mrcnn_class_loss: 0.2628 - mrcnn_bbox_loss: 0.3427 - mrcnn_mask_loss: 0.4459 - val_loss: 1.9592 - val_rpn_class_loss: 0.1897 - val_rpn_bbox_loss: 0.6667 - val_mrcnn_class_loss: 0.2808 - val_mrcnn_bbox_loss: 0.3557 - val_mrcnn_mask_loss: 0.4663
Epoch 25/80
98/98 [==============================] - 6826s 70s/step - loss: 1.9221 - rpn_class_loss: 0.2053 - rpn_bbox_loss: 0.6600 - mrcnn_class_loss: 0.2662 - mrcnn_bbox_loss: 0.3430 - mrcnn_mask_loss: 0.4476 - val_loss: 1.9084 - val_rpn_class_loss: 0.1932 - val_rpn_bbox_loss: 0.6081 - val_mrcnn_class_loss: 0.2959 - val_mrcnn_bbox_loss: 0.3448 - val_mrcnn_mask_loss: 0.4663
Epoch 26/80
98/98 [==============================] - 6817s 70s/step - loss: 1.9114 - rpn_class_loss: 0.1987 - rpn_bbox_loss: 0.6858 - mrcnn_class_loss: 0.2562 - mrcnn_bbox_loss: 0.3330 - mrcnn_mask_loss: 0.4376 - val_loss: 1.8147 - val_rpn_class_loss: 0.1948 - val_rpn_bbox_loss: 0.5914 - val_mrcnn_class_loss: 0.2571 - val_mrcnn_bbox_loss: 0.3424 - val_mrcnn_mask_loss: 0.4290
Epoch 27/80
98/98 [==============================] - 6884s 70s/step - loss: 1.9321 - rpn_class_loss: 0.2059 - rpn_bbox_loss: 0.6642 - mrcnn_class_loss: 0.2760 - mrcnn_bbox_loss: 0.3426 - mrcnn_mask_loss: 0.4435 - val_loss: 1.8004 - val_rpn_class_loss: 0.1784 - val_rpn_bbox_loss: 0.5894 - val_mrcnn_class_loss: 0.2581 - val_mrcnn_bbox_loss: 0.3523 - val_mrcnn_mask_loss: 0.4222
Epoch 28/80
98/98 [==============================] - 6846s 70s/step - loss: 1.9373 - rpn_class_loss: 0.1947 - rpn_bbox_loss: 0.6989 - mrcnn_class_loss: 0.2623 - mrcnn_bbox_loss: 0.3406 - mrcnn_mask_loss: 0.4407 - val_loss: 1.9209 - val_rpn_class_loss: 0.2133 - val_rpn_bbox_loss: 0.6392 - val_mrcnn_class_loss: 0.2749 - val_mrcnn_bbox_loss: 0.3600 - val_mrcnn_mask_loss: 0.4335
Epoch 29/80
98/98 [==============================] - 6797s 69s/step - loss: 1.8450 - rpn_class_loss: 0.1874 - rpn_bbox_loss: 0.6305 - mrcnn_class_loss: 0.2694 - mrcnn_bbox_loss: 0.3271 - mrcnn_mask_loss: 0.4304 - val_loss: 1.8663 - val_rpn_class_loss: 0.1981 - val_rpn_bbox_loss: 0.6188 - val_mrcnn_class_loss: 0.2712 - val_mrcnn_bbox_loss: 0.3503 - val_mrcnn_mask_loss: 0.4279
Epoch 30/80
98/98 [==============================] - 7024s 72s/step - loss: 1.9302 - rpn_class_loss: 0.1953 - rpn_bbox_loss: 0.6756 - mrcnn_class_loss: 0.2750 - mrcnn_bbox_loss: 0.3395 - mrcnn_mask_loss: 0.4447 - val_loss: 1.7655 - val_rpn_class_loss: 0.1537 - val_rpn_bbox_loss: 0.5584 - val_mrcnn_class_loss: 0.2874 - val_mrcnn_bbox_loss: 0.3379 - val_mrcnn_mask_loss: 0.4282
Epoch 31/80
98/98 [==============================] - 7098s 72s/step - loss: 1.8453 - rpn_class_loss: 0.1771 - rpn_bbox_loss: 0.6332 - mrcnn_class_loss: 0.2694 - mrcnn_bbox_loss: 0.3298 - mrcnn_mask_loss: 0.4357 - val_loss: 1.8434 - val_rpn_class_loss: 0.1906 - val_rpn_bbox_loss: 0.5818 - val_mrcnn_class_loss: 0.2894 - val_mrcnn_bbox_loss: 0.3542 - val_mrcnn_mask_loss: 0.4273
Epoch 32/80
98/98 [==============================] - 6911s 71s/step - loss: 1.8074 - rpn_class_loss: 0.1806 - rpn_bbox_loss: 0.6208 - mrcnn_class_loss: 0.2657 - mrcnn_bbox_loss: 0.3204 - mrcnn_mask_loss: 0.4199 - val_loss: 1.8431 - val_rpn_class_loss: 0.1859 - val_rpn_bbox_loss: 0.6054 - val_mrcnn_class_loss: 0.2772 - val_mrcnn_bbox_loss: 0.3490 - val_mrcnn_mask_loss: 0.4257
Epoch 33/80
98/98 [==============================] - 6715s 69s/step - loss: 1.8429 - rpn_class_loss: 0.1828 - rpn_bbox_loss: 0.6511 - mrcnn_class_loss: 0.2616 - mrcnn_bbox_loss: 0.3232 - mrcnn_mask_loss: 0.4243 - val_loss: 1.9343 - val_rpn_class_loss: 0.1843 - val_rpn_bbox_loss: 0.6154 - val_mrcnn_class_loss: 0.2922 - val_mrcnn_bbox_loss: 0.3809 - val_mrcnn_mask_loss: 0.4614
Epoch 34/80
98/98 [==============================] - 7003s 71s/step - loss: 1.8255 - rpn_class_loss: 0.1812 - rpn_bbox_loss: 0.6530 - mrcnn_class_loss: 0.2542 - mrcnn_bbox_loss: 0.3162 - mrcnn_mask_loss: 0.4210 - val_loss: 1.8316 - val_rpn_class_loss: 0.1614 - val_rpn_bbox_loss: 0.5735 - val_mrcnn_class_loss: 0.2950 - val_mrcnn_bbox_loss: 0.3426 - val_mrcnn_mask_loss: 0.4591
Epoch 35/80
98/98 [==============================] - 6908s 70s/step - loss: 1.8582 - rpn_class_loss: 0.1741 - rpn_bbox_loss: 0.6528 - mrcnn_class_loss: 0.2648 - mrcnn_bbox_loss: 0.3315 - mrcnn_mask_loss: 0.4350 - val_loss: 1.7017 - val_rpn_class_loss: 0.1628 - val_rpn_bbox_loss: 0.5658 - val_mrcnn_class_loss: 0.2505 - val_mrcnn_bbox_loss: 0.3141 - val_mrcnn_mask_loss: 0.4086
Epoch 36/80
98/98 [==============================] - 6967s 71s/step - loss: 1.8212 - rpn_class_loss: 0.1741 - rpn_bbox_loss: 0.6359 - mrcnn_class_loss: 0.2604 - mrcnn_bbox_loss: 0.3238 - mrcnn_mask_loss: 0.4270 - val_loss: 1.7086 - val_rpn_class_loss: 0.1645 - val_rpn_bbox_loss: 0.5474 - val_mrcnn_class_loss: 0.2678 - val_mrcnn_bbox_loss: 0.3224 - val_mrcnn_mask_loss: 0.4065
Epoch 37/80
98/98 [==============================] - 7080s 72s/step - loss: 1.8344 - rpn_class_loss: 0.1716 - rpn_bbox_loss: 0.6382 - mrcnn_class_loss: 0.2661 - mrcnn_bbox_loss: 0.3280 - mrcnn_mask_loss: 0.4306 - val_loss: 1.8383 - val_rpn_class_loss: 0.1728 - val_rpn_bbox_loss: 0.6288 - val_mrcnn_class_loss: 0.2824 - val_mrcnn_bbox_loss: 0.3357 - val_mrcnn_mask_loss: 0.4186
Epoch 38/80
98/98 [==============================] - 7043s 72s/step - loss: 1.7631 - rpn_class_loss: 0.1704 - rpn_bbox_loss: 0.6125 - mrcnn_class_loss: 0.2586 - mrcnn_bbox_loss: 0.3071 - mrcnn_mask_loss: 0.4144 - val_loss: 1.7050 - val_rpn_class_loss: 0.1667 - val_rpn_bbox_loss: 0.5390 - val_mrcnn_class_loss: 0.2602 - val_mrcnn_bbox_loss: 0.3217 - val_mrcnn_mask_loss: 0.4174
Epoch 39/80
