{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# file paths\n",
    "directory = os.getcwd()\n",
    "DATA_DIR = os.path.abspath(\"../data\")\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, 'stage1_train')\n",
    "TEST_PATH = os.path.join(DATA_DIR, 'stage1_test')\n",
    "INPUT_PATH = os.path.join(directory, 'input')\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import numpy as np\n",
    "def read_image_labels(image_id):\n",
    "    image_file = os.path.join(TRAIN_PATH, \"{}\", \"images\", \"{}.png\").format(image_id, image_id)\n",
    "    mask_file = os.path.join(TRAIN_PATH,  \"{}\", \"masks\", \"*.png\").format(image_id)\n",
    "    image = skimage.io.imread(image_file)\n",
    "    masks = skimage.io.imread_collection(mask_file).concatenate()\n",
    "    height, width, _ = image.shape\n",
    "    num_masks = masks.shape[0]\n",
    "    labels = np.zeros((height, width), np.uint16)\n",
    "    for index in range(0, num_masks):\n",
    "        labels[masks[index] > 0] = index + 1\n",
    "    return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "def data_aug(image, label, angle=30, resize_rate=0.9):\n",
    "    flip = random.randint(0, 1)\n",
    "    size = image.shape[0]\n",
    "    rsize = random.randint(np.floor(resize_rate*size),size)\n",
    "    w_s = random.randint(0,size - rsize)\n",
    "    h_s = random.randint(0,size - rsize)\n",
    "    sh = random.random()/2-0.25\n",
    "    rotate_angle = random.random()/180*np.pi*angle\n",
    "    # Create Affine transform\n",
    "    affine_tf = transform.AffineTransform(shear=sh, rotation=rotate_angle)\n",
    "    # Apply transform to image data\n",
    "    image = transform.warp(image, inverse_map=affine_tf, mode='edge')\n",
    "    label = transform.warp(label, inverse_map=affine_tf, mode='edge')\n",
    "    # Randomly cropping image frame\n",
    "    image = image[w_s:w_s+size, h_s:h_s+size, :]\n",
    "    label = label[w_s:w_s+size, h_s:h_s+size]\n",
    "    # Randomly flip frame\n",
    "    if flip:\n",
    "        image = image[:, ::-1, :]\n",
    "        label = label[:, ::-1]\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_ids = os.listdir(TRAIN_PATH)\n",
    "image_id = image_ids[random.randint(0, len(image_ids))]\n",
    "image, labels = read_image_labels(image_id)\n",
    "# original imagea\n",
    "plt.subplot(221)\n",
    "plt.imshow(image)\n",
    "plt.subplot(222)\n",
    "plt.imshow(labels)\n",
    "\n",
    "new_image, new_labels = data_aug(image, labels, angle=5, resize_rate=0.9)\n",
    "# augmented images\n",
    "plt.subplot(223)\n",
    "plt.imshow(new_image)\n",
    "plt.subplot(224)\n",
    "plt.imshow(new_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "# sample tensorflow model\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation set\n",
    "validation_ids = []\n",
    "for i in range(100):\n",
    "    idx = random.randint(0, len(train_ids))\n",
    "    rand_id = train_ids[idx]\n",
    "    train_ids.remove(rand_id)\n",
    "    validation_ids.append(rand_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = os.path.join(TRAIN_PATH, id_)\n",
    "    image_path = os.path.join(path, 'images', id_ + '.png')\n",
    "   # img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = imread(image_path)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    mask_path = os.path.join(path, 'masks')\n",
    "    for mask_file in next(os.walk(mask_path))[2]:\n",
    "        mask_file_path = os.path.join(mask_path, mask_file)\n",
    "        mask_ = imread(mask_file_path)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',\n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    path = os.path.join(TEST_PATH, id_)\n",
    "    image_path = os.path.join(path, 'images', id_ + '.png')\n",
    "    img = imread(image_path)[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize validation images and masks\n",
    "X_validation = np.zeros((len(validation_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_validation = np.zeros((len(validation_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing validation images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(validation_ids), total=len(validation_ids)):\n",
    "    path = os.path.join(TRAIN_PATH, id_)\n",
    "    image_path = os.path.join(path, 'images', id_ + '.png')\n",
    "   # img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = imread(image_path)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_validation[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    mask_path = os.path.join(path, 'masks')\n",
    "    for mask_file in next(os.walk(mask_path))[2]:\n",
    "        mask_file_path = os.path.join(mask_path, mask_file)\n",
    "        mask_ = imread(mask_file_path)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',\n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_validation[n] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle():\n",
    "    global images, labels\n",
    "    p = np.random.permutation(len(X_train))\n",
    "    images = X_train[p]\n",
    "    labels = Y_train[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_s, iters):\n",
    "    if(iters == 0):\n",
    "        shuffle()\n",
    "    count = batch_s * iters\n",
    "    return images[count:(count + batch_s)], labels[count:(count + batch_s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def deconv2d(input_tensor, filter_size, output_size, out_channels, in_channels, name, strides = [1, 1, 1, 1]):\n",
    "    dyn_input_shape = tf.shape(input_tensor)\n",
    "    batch_size = dyn_input_shape[0]\n",
    "    out_shape = tf.stack([batch_size, output_size, output_size, out_channels])\n",
    "    filter_shape = [filter_size, filter_size, out_channels, in_channels]\n",
    "    w = tf.get_variable(name=name, shape=filter_shape)\n",
    "    h1 = tf.nn.conv2d_transpose(input_tensor, w, out_shape, strides, padding='VALID')\n",
    "    return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_tensor, depth, kernel, name, strides=(1, 1), padding=\"VALID\"):\n",
    "    return tf.layers.conv2d(input_tensor, filters=depth, kernel_size=kernel, strides=strides, padding=padding, activation=tf.nn.relu, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 128, 128, 3])\n",
    "Y_ = tf.placeholder(tf.float32, [None, 128, 128, 1])\n",
    "lr = tf.placeholder(tf.float32)\n",
    "\n",
    "net = conv2d(X, 33, 1, \"Y0\")\n",
    "\n",
    "net = conv2d(net, 33, 2, \"Y1\", strides=(2, 2))\n",
    "\n",
    "net = conv2d(net, 33, 2, \"Y2\", strides=(2, 2))\n",
    "\n",
    "\n",
    "net = deconv2d(net, 1, 32, 33, 33, \"Y2_deconv\")\n",
    "net = tf.nn.relu(net)\n",
    "\n",
    "net = deconv2d(net, 2, 64, 33, 33, \"Y1_deconv\", strides=[1, 2, 2, 1])\n",
    "net = tf.nn.relu(net)\n",
    "\n",
    "net = deconv2d(net, 2, 128, 27, 33, \"Y0_deconv\", strides=[1, 2, 2, 1])\n",
    "net = tf.nn.relu(net)\n",
    "\n",
    "\n",
    "logits = deconv2d(net, 1, 128, 1, 27, \"logits_deconv\")\n",
    "loss = tf.losses.sigmoid_cross_entropy(Y_, logits)\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no augmentation\n",
    "batch_count = 0\n",
    "display_count = 1\n",
    "for i in range(10):\n",
    "    # training on batches of 10 images with 10 mask images\n",
    "    if (batch_count > 57):\n",
    "        batch_count = 0\n",
    "\n",
    "    batch_X, batch_Y = next_batch(10, batch_count)\n",
    "\n",
    "    batch_count += 1\n",
    "\n",
    "    feed_dict = {X: batch_X, Y_: batch_Y, lr: 0.0005}\n",
    "    loss_value, _ = sess.run([loss, optimizer], feed_dict=feed_dict)\n",
    "\n",
    "    if (i % 10 == 0):\n",
    "        print(str(display_count) + \" training loss:\", str(loss_value))\n",
    "        display_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with augmentation\n",
    "batch_count = 0\n",
    "display_count = 1\n",
    "for i in range(100):\n",
    "    # training on batches of 10 images with 10 mask images\n",
    "    if (batch_count > 57):\n",
    "        batch_count = 0\n",
    "\n",
    "    batch_X, batch_Y = next_batch(10, batch_count)\n",
    "\n",
    "    # transform images in batch\n",
    "    for j in range(len(batch_X)):\n",
    "        for k in range(10):\n",
    "            new_image, new_labels = data_aug(batch_X[j], batch_Y[j])\n",
    "            np.append(batch_X, new_image)\n",
    "            np.append(batch_Y, new_labels)\n",
    "\n",
    "    batch_count += 1\n",
    "\n",
    "    feed_dict = {X: batch_X, Y_: batch_Y, lr: 0.0005}\n",
    "    loss_value, _ = sess.run([loss, optimizer], feed_dict=feed_dict)\n",
    "\n",
    "    if (i % 10 == 0):\n",
    "        print(str(display_count) + \" training loss:\", str(loss_value))\n",
    "        display_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at test image\n",
    "from skimage.io import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "ix = random.randint(0, len(X_test))\n",
    "test_image = X_test[ix]\n",
    "plt.subplot(121)\n",
    "imshow(test_image)\n",
    "\n",
    "test_image = np.reshape(test_image, [-1, 128 , 128, 3])\n",
    "test_data = {X:test_image}\n",
    "\n",
    "test_mask = sess.run([logits], feed_dict=test_data)\n",
    "test_mask = np.reshape(np.squeeze(test_mask), [IMG_WIDTH, IMG_WIDTH, 1])\n",
    "for i in range(IMG_WIDTH):\n",
    "    for j in range(IMG_HEIGHT):\n",
    "            test_mask[i][j] = int(sigmoid(test_mask[i][j])*255)\n",
    "plt.subplot(122)\n",
    "imshow(test_mask.squeeze().astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get validation results\n",
    "feed_dict = {X: X_validation, Y_: Y_validation, lr: 0.0005}\n",
    "loss_value, _ = sess.run([loss, optimizer], feed_dict=feed_dict)\n",
    "print(\"Validation loss \" + str(loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at validation image\n",
    "# actual image, actual mask, predicted mask\n",
    "from skimage.io import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "ix = random.randint(0, len(X_validation))\n",
    "val_image = X_validation[ix]\n",
    "plt.subplot(131)\n",
    "imshow(val_image)\n",
    "\n",
    "val_image_id = validation_ids[ix]\n",
    "_, labels = read_image_labels(val_image_id)\n",
    "plt.subplot(132)\n",
    "imshow(labels)\n",
    "\n",
    "val_image = np.reshape(val_image, [-1, 128 , 128, 3])\n",
    "test_data = {X:val_image}\n",
    "\n",
    "test_mask = sess.run([logits], feed_dict=test_data)\n",
    "test_mask = np.reshape(np.squeeze(test_mask), [IMG_WIDTH, IMG_WIDTH, 1])\n",
    "for i in range(IMG_WIDTH):\n",
    "    for j in range(IMG_HEIGHT):\n",
    "            test_mask[i][j] = int(sigmoid(test_mask[i][j])*255)\n",
    "plt.subplot(133)\n",
    "imshow(test_mask.squeeze().astype(np.uint8))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
